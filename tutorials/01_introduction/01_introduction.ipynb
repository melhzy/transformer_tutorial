```jupyter notebook name=01_introduction.ipynb url=https://github.com/melhzy/transformer_tutorial/blob/b37cb8f382fbc2b6fdaae8172c7c8473966a5591/tutorials/01_introduction/01_introduction.ipynb
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Introduction and Setup\n",
    "\n",
    "Welcome to the Transformer Tutorial series! This set of notebooks will guide you through the foundations, implementation, and applications of transformer-based models in deep learning. By the end, you'll be equipped to understand and build state-of-the-art architectures like BERT and GPT.\n",
    "\n",
    "## What Are Transformers?\n",
    "Transformers are neural network architectures that leverage self-attention mechanisms to process sequential data efficiently. They have revolutionized Natural Language Processing and are increasingly applied to fields like computer vision and reinforcement learning.\n",
    "\n",
    "### Key Topics Covered:\n",
    "- Brief history and motivation for transformers\n",
    "- Hardware/software environment setup\n",
    "- Installing core dependencies\n",
    "- Project structure overview\n",
    "- Running and modifying notebooks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "\n",
    "Before starting, ensure you are familiar with basic Python and deep learning concepts (e.g., tensors, backpropagation). A working knowledge of PyTorch will be helpful but not required.\n",
    "\n",
    "- Recommended: Python 3.8+\n",
    "- GPU (NVIDIA CUDA) support recommended for faster training\n",
    "- (Optional) Familiarity with Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup\n",
    "\n",
    "We recommend setting up a virtual environment to avoid dependency conflicts. You can use **virtualenv** or **conda** for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using virtualenv (Linux/Mac/Windows)\n",
    "!pip install virtualenv\n",
    "!virtualenv venv\n",
    "# Activate it:\n",
    "# Linux/Mac: source venv/bin/activate\n",
    "# Windows: venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer **conda**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using conda (Anaconda/Miniconda)\n",
    "!conda create -n transformer-env python=3.10\n",
    "!conda activate transformer-env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Requirements\n",
    "\n",
    "We'll use PyTorch and Hugging Face Transformers as our main frameworks. Other useful libraries include datasets, matplotlib (for visualization), and tqdm (for progress bars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main libraries\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install transformers datasets tqdm matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using CUDA (GPU acceleration), refer to [PyTorch's installation guide](https://pytorch.org/get-started/locally/) for the correct commands for your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Project Structure\n",
    "\n",
    "Here's how this repository is organized:\n",
    "```\n",
    "transformer_tutorial/\n",
    "├── tutorials/\n",
    "│   ├── 01_introduction/\n",
    "│   ├── 02_attention/\n",
    "│   ├── ...\n",
    "├── requirements.txt\n",
    "├── README.md\n",
    "└── ...\n",
    "```\n",
    "Each `tutorials` subdirectory contains a focused notebook dedicated to a specific topic. The `requirements.txt` file lists all dependencies if you want to install them with `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running the Notebooks\n",
    "\n",
    "You can run these notebooks locally or on cloud platforms like [Google Colab](https://colab.research.google.com/) or [Kaggle Kernels](https://www.kaggle.com/kernels).\n",
    "\n",
    "To start Jupyter Notebook:\n",
    "```bash\n",
    "pip install notebook\n",
    "jupyter notebook\n",
    "```\n",
    "Or with Jupyter Lab:\n",
    "```bash\n",
    "pip install jupyterlab\n",
    "jupyter lab\n",
    "```\n",
    "Follow the launcher instructions to open `tutorials/01_introduction/01_introduction.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Tips for Success\n",
    "\n",
    "- Read and follow the comments and documentation in each notebook.\n",
    "- Experiment by changing code and re-running cells.\n",
    "- If you are stuck, consult the official [PyTorch](https://pytorch.org/docs/stable/index.html) and [Transformers](https://huggingface.co/docs/transformers/index) documentation.\n",
    "- Ask for help in the respective GitHub Issues or Discussion tabs.\n",
    "- (Optional) Version control your notebooks using git to track your learning progress.\n",
    "\n",
    "---\n",
    "Ready? Continue to the next tutorial for a deep dive into **attention mechanisms**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

```
